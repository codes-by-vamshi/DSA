{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "  def __init__(self,key,value):\n",
        "    self.key = key\n",
        "    self.value = value\n",
        "    self.next = None"
      ],
      "metadata": {
        "id": "CiX_aK5AcVAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HashTableChain:\n",
        "    def __init__(self, size, file):\n",
        "        self.size = size\n",
        "        self.table = [None] * size\n",
        "        self.g = 31  # positive constant\n",
        "        with open(file,'r') as f:\n",
        "          for line in f:\n",
        "            self.insert(line.strip(),1)\n",
        "        with open('Chaining.txt','w') as f:\n",
        "          for i in range(self.size):\n",
        "            temp = self.table[i]\n",
        "            while temp!=None:\n",
        "              f.write(f'{temp.key}: {temp.value}\\n')\n",
        "              temp = temp.next\n",
        "\n",
        "    # hash function to determine the index for a given key\n",
        "    def hash_function(self, key):\n",
        "        hash = 0\n",
        "        n = len(key)\n",
        "        for i in range(n):\n",
        "          hash = (self.g * hash) + ord(key[i])\n",
        "        index = hash % self.size\n",
        "        return index\n",
        "\n",
        "    # insert a key-value pair to the hash table\n",
        "    def insert(self, key, value):\n",
        "        hash_val = self.hash_function(key)\n",
        "        if(self.table[hash_val] == None):\n",
        "          node = Node(key,value)\n",
        "          self.table[hash_val] = node\n",
        "        else:\n",
        "          temp = self.table[hash_val]\n",
        "          while temp.key != key and temp.next != None:\n",
        "            temp = temp.next\n",
        "          if(temp.key != key and temp.next == None):\n",
        "            node = Node(key,value)\n",
        "            temp.next = node\n",
        "          else:\n",
        "            temp.value = temp.value + value\n",
        "\n",
        "    # retrieve the value for a given key\n",
        "    def search(self, key):\n",
        "        index = self.hash_function(key)\n",
        "        val = None\n",
        "        myNode = self.table[index]\n",
        "        while myNode != None:\n",
        "          if(myNode.key == key):\n",
        "            val = myNode.value\n",
        "            break\n",
        "          myNode = myNode.next\n",
        "        return val\n",
        "\n",
        "    def delete(self, key):\n",
        "        hash_val = self.hash_function(key)\n",
        "        temp1 = self.table[hash_val]\n",
        "        temp2 = None\n",
        "        while temp1 != None:\n",
        "          if(temp1.key == key):\n",
        "            if(temp2 == None):\n",
        "              self.table[hash_val] = temp1.next\n",
        "            else:\n",
        "              temp2.next = temp1.next\n",
        "            return temp1.value\n",
        "          temp2 = temp1\n",
        "          temp1 = temp1.next\n",
        "        return None"
      ],
      "metadata": {
        "id": "3uBPFjclQAYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Strategy Used - **Chaining**\n",
        "\n",
        "Primary Data Structure is **Hash Table** represented as a list(self.table) of a specified size(self.size), here i am using 58111.(check at the end of file)\n",
        "\n",
        "Each element in self.table stores reference to a **LinkedList**.\n",
        "\n",
        "When a collision occurs, we append the data to the end of linkedlist corresponding to index in hash table if the key doesn't exist already with value = 1, else we find the node with the given key at corresponding index then we increament the value by 1.\n",
        "\n",
        "The **value** tells about the **frequency** about the **key**"
      ],
      "metadata": {
        "id": "V5DHYqzQjGZR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwVQ_Al7PZfe"
      },
      "outputs": [],
      "source": [
        "class HashTableLinProb:\n",
        "    def __init__(self, size, file):\n",
        "        self.size = size\n",
        "        self.table = [None] * size\n",
        "        self.g = 31  # positive constant\n",
        "        with open(file,'r') as f:\n",
        "          for line in f:\n",
        "            self.insert(line.strip(),1)\n",
        "        with open('Probing.txt','w') as f:\n",
        "          for i in range(self.size):\n",
        "            temp = self.table[i]\n",
        "            if(temp!=None and temp[0]!='---Deleted Node---'):\n",
        "              f.write(f'{temp[0]}: {temp[1]}\\n')\n",
        "\n",
        "    # hash function to determine the index for a given key\n",
        "    def hash_function(self, key):\n",
        "        hash = 0\n",
        "        n = len(key)\n",
        "        for i in range(n):\n",
        "          hash = (self.g * hash) + ord(key[i])\n",
        "        index = hash % self.size\n",
        "        return index\n",
        "\n",
        "    # insert a key-value pair to the hash table\n",
        "    def insert(self, key, value):\n",
        "        hash_val = self.hash_function(key)\n",
        "        temp = self.table[hash_val]\n",
        "        while temp != None:\n",
        "          if(temp[0] == key):\n",
        "            break\n",
        "          hash_val = (hash_val + 1) % self.size\n",
        "          temp = self.table[hash_val]\n",
        "        if(temp == None):\n",
        "          self.table[hash_val] = (key,value)\n",
        "        else:\n",
        "          self.table[hash_val] = (key,self.table[hash_val][1]+1)\n",
        "\n",
        "    # retrieve the value for a given key\n",
        "    def search(self, key):\n",
        "        index = self.hash_function(key)\n",
        "        val = None\n",
        "        count = 0\n",
        "        while count < self.size:\n",
        "          if(self.table[index][0] == key):\n",
        "            val = self.table[index][1]\n",
        "            break\n",
        "          index = (index+1)%self.size\n",
        "          count+=1\n",
        "        return val\n",
        "\n",
        "    def delete(self, key):\n",
        "        index = self.hash_function(key)\n",
        "        val = None\n",
        "        count = 0\n",
        "        while count < self.size:\n",
        "          if(self.table[index][0] == key):\n",
        "            val = self.table[index][1]\n",
        "            self.table[index] = ('---Deleted Node---',1)\n",
        "            break\n",
        "          index = (index+1)%self.size\n",
        "          count+=1\n",
        "        return val"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Strategy Used - **Linear Probing**\n",
        "\n",
        "Data Structure used is **Array**(List in Python). Here Im using of size 58111.(check end of file) Each element in List is a **tuple (key, value)**, where **value** tells about **frequency** of key\n",
        "\n",
        "When a collision occurs, we check if collision is of same key if yes we increment the value, else we go to next slot and repeat the same process but if we get an empty slot then we insert the tuple (key,1) as key didn't present earlier.\n",
        "\n",
        "One important thing I did in deletion is that I am not making that slot available to insert once its deleted as it causes the following problem:\n",
        "\n",
        "Suppose word1 and word2 produces same hash value, so i got word1 for first time its hash value by k, suppose k in hash table be None so I inserted (word1,1) at k, now when word2 is inserted it would get inserted at next availble slot after k as k is already full and let it be l with (word2,1) now if I delete word1, slot k becomes empty and after that if I try to insert word2 it goes to slot k as it is empty and it will cause duplicates for that reason when ever a delete is performed im replacing slot with ('---Deleted Node---',1), so nothing gets inserted there."
      ],
      "metadata": {
        "id": "QcZAUBnbklc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HashTableDoubleHash:\n",
        "    def __init__(self, size, file):\n",
        "        self.size = size\n",
        "        self.table = [None] * size\n",
        "        self.g = 31  # positive constant\n",
        "        with open(file,'r') as f:\n",
        "          for line in f:\n",
        "            self.insert(line.strip(),1)\n",
        "        with open('DoubleHashing.txt','w') as f:\n",
        "          for i in range(self.size):\n",
        "            temp = self.table[i]\n",
        "            if(temp!=None and temp[0]!='---Deleted Node---'):\n",
        "              f.write(f'{temp[0]}: {temp[1]}\\n')\n",
        "\n",
        "    # hash function to determine the index for a given key\n",
        "    def hash_function(self, key):\n",
        "        hash = 0\n",
        "        n = len(key)\n",
        "        for i in range(n):\n",
        "          hash = (self.g * hash) + ord(key[i])\n",
        "        index = hash % self.size\n",
        "        return index\n",
        "\n",
        "    def secondary_hash_function(self, key):\n",
        "        return (7*key+11) % self.size\n",
        "\n",
        "    # insert a key-value pair to the hash table\n",
        "    def insert(self, key, value):\n",
        "        hash_val = self.hash_function(key)\n",
        "        temp = self.table[hash_val]\n",
        "        newHash = [hash_val]\n",
        "        while(temp!=None):\n",
        "          if(temp[0] == key):\n",
        "            break\n",
        "          hash_val = (self.secondary_hash_function(hash_val))%self.size\n",
        "          temp = self.table[hash_val]\n",
        "        if(temp == None):\n",
        "          self.table[hash_val] = (key,value)\n",
        "        else:\n",
        "          self.table[hash_val] = (key, self.table[hash_val][1]+1)\n",
        "\n",
        "    # retrieve the value for a given key\n",
        "    def search(self, key):\n",
        "        hash_val = self.hash_function(key)\n",
        "        val = None\n",
        "        count = 0\n",
        "        while count < self.size:\n",
        "          if(self.table[hash_val][0] == key):\n",
        "            val = self.table[hash_val][1]\n",
        "            break\n",
        "          hash_val = (self.secondary_hash_function(hash_val))%self.size\n",
        "          count+=1\n",
        "        return val\n",
        "\n",
        "    def delete(self, key):\n",
        "        hash_val = self.hash_function(key)\n",
        "        val = None\n",
        "        count = 0\n",
        "        while count < self.size:\n",
        "          if(self.table[hash_val][0] == key):\n",
        "            val = self.table[hash_val][1]\n",
        "            self.table[hash_val] = ('---Deleted Node---',1)\n",
        "            break\n",
        "          hash_val = (self.secondary_hash_function(hash_val))%self.size\n",
        "          count+=1\n",
        "        return val"
      ],
      "metadata": {
        "id": "WJkUl0gkPk34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Strategy Used - **Double Hashing**\n",
        "\n",
        "Data Structure used is **Array**(List in Python). Here Im using of size 158111.(check end of file) Each element in List is a **tuple (key, value)**, where **value** tells about **frequency** of key\n",
        "\n",
        "When a collision occurs, we check if collision is of same key if yes we increment the value, else we apply second hash and see if its None then insert else if in collision if key is same then increment the value else repeatedly apply secondary hash function.\n",
        "\n",
        "Similar to Linear Probing, I did in deletion is that I am not making that slot available to insert once its deleted as it causes the following problem:\n",
        "\n",
        "Suppose word1 and word2 produces same hash value, so i got word1 for first time its hash value by k, suppose k in hash table be None so I inserted (word1,1) at k, now when word2 is inserted it would get inserted at next availble slot after k as k is already full and let it be l with (word2,1) now if I delete word1, slot k becomes empty and after that if I try to insert word2 it goes to slot k as it is empty and it will cause duplicates for that reason when ever a delete is performed im replacing slot with ('---Deleted Node---',1), so nothing gets inserted there."
      ],
      "metadata": {
        "id": "wp9dzZjc8eQq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Here I have given sizes for 3 hashTables and initialized all 3 objects so 3 files \"Chaining.txt\", \"Probing.txt\" and \"DoubleHashing.txt\" files for frequency from \"dictionary.txt\" are generated."
      ],
      "metadata": {
        "id": "cfdzOrr6HCkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  HashTableChain(58111,'dictionary.txt')\n",
        "  HashTableLinProb(58111,'dictionary.txt')\n",
        "  HashTableDoubleHash(158111,'dictionary.txt')"
      ],
      "metadata": {
        "id": "leMhVMoPjsa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### See as I already know there are 58110 unique words(calculated separately) in dictionary.txt file, so I have kept size of table to be nearest prime number i.e., 58111.\n",
        "\n",
        "### In Chianing it worked as whenever there's a collision, chaining is happening.\n",
        "\n",
        "### In Linear Probing also it worked as whenever there's a collision, we are finding next available empty slot as we know the unique elements are less than size here, it worked\n",
        "\n",
        "### 58111 didn't worked for Double Hashing, as the double hasing is going to infinte loop i.e., its only giving values which already are full which is expected as 58111 size and we cant expect hash function to give 58110 unique values but as soon as I increased the size to 158111 i.e, I increased the size by 1 lakh, it was able to generate 58110 unique keys and the problem solved."
      ],
      "metadata": {
        "id": "8gCP4pqbHqJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pros and Cons**\n",
        "\n",
        "### **Chaining**\n",
        "\n",
        "#### Pros\n",
        "Handle high number of keys efficiently as long as load factor is not too high\n",
        "\n",
        "#### Cons\n",
        "When load factor becomes high, linked list can become too big to search\n",
        "\n",
        "### **Linear Probing**\n",
        "\n",
        "#### Pros\n",
        "Easy to implement\n",
        "\n",
        "#### Cons\n",
        "Deleting makes the index not usable, so space is getting wasted\n",
        "\n",
        "### **Double Hashing**\n",
        "\n",
        "#### Pros\n",
        "Better Distribution of Keys\n",
        "\n",
        "#### Cons\n",
        "Complicated to implement and if size is not enough it might end up in infintie loop\n",
        "\n"
      ],
      "metadata": {
        "id": "o3YNPmAzJAgz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a5ur5wVxJFui"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}